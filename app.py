import subprocess
import sys

# ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
def install_packages():
    packages = ['flask', 'telethon', 'transformers', 'torch']
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            print(f"ðŸ“¦ Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_packages()

from flask import Flask
from threading import Thread
import os
from telethon import TelegramClient, events
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import re

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Flask Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
app = Flask('')

@app.route('/')
def home():
    return "ðŸ¤– Ð‘Ð¾Ñ‚ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚!"

def run_web():
    app.run(host='0.0.0.0', port=8080)

# Ð—Ð°Ð¿ÑƒÑÐº Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ð° Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
Thread(target=run_web).start()

# Ð”ÐÐÐÐ«Ð• ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð¯
api_id = 20382032
api_hash = '5c84aab2e75919ee24d15c15f76419e8'
bot_token = os.environ.get('BOT_TOKEN', '8551425125:AAEnKEEM6Dk5KdLuJfjHm7IjkQeKvqFivn8')

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
client = TelegramClient('bot_session', api_id, api_hash).start(bot_token=bot_token)

print("âš¡ Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð‘ÐžÐ¢Ð Ð”Ð›Ð¯ Ð§ÐÐ¢ÐžÐ’...")
print("ðŸŒ Ð’ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸")

try:
    tokenizer = AutoTokenizer.from_pretrained("sberbank-ai/rugpt3small_based_on_gpt2")
    model = AutoModelForCausalLM.from_pretrained("sberbank-ai/rugpt3mall_based_on_gpt2")
    model_loaded = True
    print("âœ… ÐœÐžÐ”Ð•Ð›Ð¬ Ð—ÐÐ“Ð Ð£Ð–Ð•ÐÐ")
except Exception as e:
    print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
    model_loaded = False

def generate_short_response(text, user_id):
    """ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð»Ñ Ñ‡Ð°Ñ‚Ð¾Ð²"""
    
    if model_loaded:
        try:
            prompt = f"Ð§ÐµÐ»Ð¾Ð²ÐµÐº: {text}\nÐ‘Ð¾Ñ‚:"
            
            inputs = tokenizer.encode(
                prompt, 
                return_tensors='pt', 
                max_length=128, 
                truncation=True
            )
            
            with torch.no_grad():
                response_ids = model.generate(
                    inputs,
                    max_new_tokens=40,
                    do_sample=True,
                    temperature=0.9,
                    top_k=30,
                    top_p=0.85,
                    repetition_penalty=1.1,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            generated_tokens = response_ids[0][inputs.shape[1]:]
            response = tokenizer.decode(generated_tokens, skip_special_tokens=True)
            
            # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ Ð´Ð¾ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
            for end_marker in ['.', '!', '?', '\n']:
                if end_marker in response:
                    response = response.split(end_marker)[0] + end_marker
                    break
            
            if len(response) > 80:
                response = response[:80].strip()
            
            if not response or len(response) < 2:
                response = generate_quick_response(text)
            
            return response.strip()
            
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {e}")
            return generate_quick_response(text)
    else:
        return generate_quick_response(text)

def generate_quick_response(text):
    """Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð»Ñ Ñ‡Ð°Ñ‚Ð¾Ð²"""
    
    text_lower = text.lower()
    
    if any(word in text_lower for word in ['Ð¿Ñ€Ð¸Ð²ÐµÑ‚', 'Ñ…Ð°Ð¹', 'hello', 'Ð·Ð´Ñ€Ð°Ð²ÑÑ‚Ð²']):
        responses = ["ÐŸÑ€Ð¸Ð²ÐµÑ‚!", "Ð—Ð´Ð°Ñ€Ð¾Ð²!", "Ð¥Ð°Ð¹!", "ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽ"]
    
    elif any(word in text_lower for word in ['ÐºÐ°Ðº Ð´ÐµÐ»Ð°', 'ÐºÐ°Ðº Ñ‚Ñ‹']):
        responses = ["ÐÐ¾Ñ€Ð¼", "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾", "Ð’ÑÐµ Ð¾Ðº", "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾"]
    
    elif any(word in text_lower for word in ['Ð¿Ð¾ÐºÐ°', 'Ð´Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½']):
        responses = ["ÐŸÐ¾ÐºÐ°!", "Ð”Ð¾ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸", "Ð‘Ñ‹Ð²Ð°Ð¹", "Ð£Ð²Ð¸Ð´Ð¸Ð¼ÑÑ"]
    
    elif any(word in text_lower for word in ['Ñ‡Ñ‚Ð¾', 'ÐºÐ°Ðº', 'Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ']):
        responses = ["ÐÐµ Ð·Ð½Ð°ÑŽ", "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾", "Ð¥Ð¼...", "Ð¡Ð¿Ñ€Ð¾ÑÐ¸ ÐµÑ‰Ðµ"]
    
    else:
        responses = [
            "ÐŸÐ¾Ð½ÑÐ»", "Ð¯ÑÐ½Ð¾", "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾", "Ð¥Ð¼...", "ÐÐ³Ð°", 
            "Ð£Ð³Ñƒ", "ÐÑƒ", "Ð”Ð°", "ÐÐµÑ‚", "ÐžÐº", "Ð›Ð¾Ð»", "ÐšÐµÐº"
        ]
    
    import random
    return random.choice(responses)

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð´Ð»Ñ Ð›Ð˜Ð§ÐÐ«Ð¥ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
@client.on(events.NewMessage(incoming=True, func=lambda e: e.is_private))
async def handle_private_message(event):
    if not event.out:
        user_id = event.sender_id
        user_message = event.text
        
        print(f"ðŸ“¨ Ð›Ð˜Ð§ÐÐžÐ• Ð¾Ñ‚ {user_id}: {user_message}")
        
        try:
            response = generate_short_response(user_message, user_id)
            await event.reply(response)
            print(f"âœ… ÐžÐ¢Ð’Ð•Ð¢: {response}")
        except Exception as e:
            await event.reply("ÐžÐº")
            print(f"âš ï¸ {e}")

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð´Ð»Ñ Ð“Ð Ð£ÐŸÐŸÐžÐ’Ð«Ð¥ Ñ‡Ð°Ñ‚Ð¾Ð²
@client.on(events.NewMessage(incoming=True, func=lambda e: not e.is_private))
async def handle_group_message(event):
    if not event.out:
        chat_id = event.chat_id
        user_id = event.sender_id
        user_message = event.text
        
        # ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð±Ð¾Ñ‚Ð° ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÐ»Ð¸ Ð¸Ð»Ð¸ ÑÑ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
        me = await client.get_me()
        if f'@{me.username}' in user_message or event.is_reply:
            print(f"ðŸ‘¥ Ð“Ð Ð£ÐŸÐŸÐ {chat_id} Ð¾Ñ‚ {user_id}: {user_message}")
            
            try:
                response = generate_short_response(user_message, user_id)
                await event.reply(response)
                print(f"âœ… ÐžÐ¢Ð’Ð•Ð¢ Ð’ Ð“Ð Ð£ÐŸÐŸÐ•: {response}")
            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ðµ: {e}")

print("=" * 50)
print("ðŸš€ Ð‘ÐžÐ¢ Ð—ÐÐŸÐ£Ð©Ð•Ð Ð”Ð›Ð¯ Ð§ÐÐ¢ÐžÐ’")
print("âœ… Ð›Ð˜Ð§ÐÐ«Ð• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯: Ð’ÐšÐ›")
print("âœ… Ð“Ð Ð£ÐŸÐŸÐžÐ’Ð«Ð• Ð§ÐÐ¢Ð«: Ð’ÐšÐ› (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¸ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¸)")
print("ðŸŒ Ð’Ð•Ð‘-Ð¡Ð•Ð Ð’Ð•Ð : ÐÐšÐ¢Ð˜Ð’Ð•Ð")
print("=" * 50)

client.run_until_disconnected()
